{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMU NLP Course—Homework 2\n",
    "## Joseph Schueder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tIn Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)\n",
    "\n",
    "2.\tAfter consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above.\n",
    "\n",
    "3.\tNow create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in arg:\n",
    "        \n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using the formula \n",
    "    for vsize in vocab_size:\n",
    "        vocab_size_norm = np.append(vocab_size_norm,(vsize - vocab_size.min()) /\n",
    "                                                    (vocab_size.max() - vocab_size.min()))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm,vocab_size_norm_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_long_vocab_size(textlist, n):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in textlist:\n",
    "        #lower case it all\n",
    "        V = set(word.lower() for word in text)\n",
    "        #limit it to just the long words\n",
    "        word_len = ''\n",
    "        text = text.split(\" \")\n",
    "        for x in text:\n",
    "            if len(x) > n:\n",
    "                word_len = word_len + x\n",
    "        text = word_len \n",
    "        #same as normal formula\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using the formula \n",
    "    for vsize in vocab_size:\n",
    "        vocab_size_norm = np.append(vocab_size_norm,(vsize - vocab_size.min()) /\n",
    "                                                    (vocab_size.max() - vocab_size.min()))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm,vocab_size_norm_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some corpuses to get average word count. This will be used to later get word counts of those and then to normalize them. This normalization will then be applied to the word count of any inputed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se ...\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop ...\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl ...\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr ...\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun ...\n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "textlist = []\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')\n",
    "    textlist.append(webtext.raw(fileid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)\n",
    "\n",
    "I passed the example normalizer a nltk library of texts to establish the normalized values. The function uses min max scaler. This method takes all the lenghts of the text and transforms them to values between 0 and 1. Variables that are measured at different scales do not contribute equally to the model fitting & model learned function and might end up creating a bias. Thus, to deal with this potential problem feature-wise normalization such as MinMax Scaling is usually used prior to model fitting(https://stackoverflow.com/questions/62178888/can-someone-explain-to-me-how-minmaxscaler-works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizer,vocab_size_normr,vocab_size_norm_sklearnr = n_vocab_size(textlist[0], textlist[1],textlist[2], textlist[3], textlist[4], textlist[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_names</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>normalized_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firefox.txt</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grail.txt</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overheard.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pirates.txt</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singles.txt</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_names  vocab_size  normalized_size\n",
       "0    firefox.txt       117.0         1.000000\n",
       "1      grail.txt        76.0         0.046512\n",
       "2  overheard.txt        88.0         0.325581\n",
       "3    pirates.txt        74.0         0.000000\n",
       "4    singles.txt        77.0         0.069767\n",
       "5       wine.txt        88.0         0.325581"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'text_names': webtext.fileids(), 'vocab_size':vocab_sizer,'normalized_size':vocab_size_norm_sklearnr}\n",
    "d\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizelr,vocab_size_normlr,vocab_size_norm_sklearnlr = n_long_vocab_size(textlist, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_names</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>normalized_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firefox.txt</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grail.txt</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overheard.txt</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pirates.txt</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singles.txt</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine.txt</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_names  vocab_size  normalized_size\n",
       "0    firefox.txt        98.0         1.000000\n",
       "1      grail.txt        56.0         0.066667\n",
       "2  overheard.txt        81.0         0.622222\n",
       "3    pirates.txt        66.0         0.288889\n",
       "4    singles.txt        55.0         0.044444\n",
       "5       wine.txt        53.0         0.000000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = {'text_names': webtext.fileids(), 'vocab_size':vocab_sizelr,'normalized_size':vocab_size_norm_sklearnlr}\n",
    "d2\n",
    "df2 = pd.DataFrame(d2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1.\n",
    "\n",
    "When we use the difficulty score as a combination of the three different measures, the normalized scores from this week tend to be higher values than the lexical diversity score thus they are driving those texts to have higher values still. I cannot see much difference by combining the three metrics together this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(textlist):\n",
    "    lex_list = []\n",
    "    for text in textlist:\n",
    "        lex_list.append(len(set(text)) / len(text))\n",
    "    return lex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0002072259879100462,\n",
       " 0.001169176807224282,\n",
       " 0.00010600902522292011,\n",
       " 0.0007759416156362721,\n",
       " 0.0036146840672237348,\n",
       " 0.0005875597574980637]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_list = lexical_diversity(textlist)\n",
    "lex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_names</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>normalized_size</th>\n",
       "      <th>normal_long</th>\n",
       "      <th>lex_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firefox.txt</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grail.txt</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overheard.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pirates.txt</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singles.txt</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_names  vocab_size  normalized_size  normal_long  lex_score\n",
       "0    firefox.txt       117.0         1.000000     1.000000   0.000207\n",
       "1      grail.txt        76.0         0.046512     0.066667   0.001169\n",
       "2  overheard.txt        88.0         0.325581     0.622222   0.000106\n",
       "3    pirates.txt        74.0         0.000000     0.288889   0.000776\n",
       "4    singles.txt        77.0         0.069767     0.044444   0.003615\n",
       "5       wine.txt        88.0         0.325581     0.000000   0.000588"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = {'text_names': webtext.fileids(), 'vocab_size':vocab_sizer,'normalized_size':vocab_size_norm_sklearnr, 'normal_long': vocab_size_norm_sklearnlr, 'lex_score': lex_list}\n",
    "d3\n",
    "df3 = pd.DataFrame(d3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_names</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>normalized_size</th>\n",
       "      <th>normal_long</th>\n",
       "      <th>lex_score</th>\n",
       "      <th>diff_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firefox.txt</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.666736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grail.txt</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.038116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overheard.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.315970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pirates.txt</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.096555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singles.txt</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.039276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine.txt</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.108723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_names  vocab_size  normalized_size  normal_long  lex_score  \\\n",
       "0    firefox.txt       117.0         1.000000     1.000000   0.000207   \n",
       "1      grail.txt        76.0         0.046512     0.066667   0.001169   \n",
       "2  overheard.txt        88.0         0.325581     0.622222   0.000106   \n",
       "3    pirates.txt        74.0         0.000000     0.288889   0.000776   \n",
       "4    singles.txt        77.0         0.069767     0.044444   0.003615   \n",
       "5       wine.txt        88.0         0.325581     0.000000   0.000588   \n",
       "\n",
       "   diff_score  \n",
       "0    0.666736  \n",
       "1    0.038116  \n",
       "2    0.315970  \n",
       "3    0.096555  \n",
       "4    0.039276  \n",
       "5    0.108723  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['diff_score'] = (df3['normalized_size'] + df3['lex_score'] + df3['normal_long']) / 3\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'14640-8.txt', \"r\")  \n",
    "\n",
    "book1 = \"\"\n",
    "for x in f:\n",
    "    book1 = book1 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('ML7331': conda)",
   "language": "python",
   "name": "python37164bitml7331condaf5c5c353a7fa46f5b783ad99991c2b10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
